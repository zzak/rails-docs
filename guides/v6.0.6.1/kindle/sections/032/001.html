<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>2 Cache Stores</title>
<link rel="stylesheet" type="text/css" href="/home/rails/v6.0.6.1/guides/output/kindle/stylesheets/kindle.css">
</head>
<body>
<h3 id="cache-stores"><a class="anchorlink" href="#cache-stores">2 Cache Stores</a></h3>
<p>Rails provides different stores for the cached data (apart from SQL and page
caching).</p>

<h4 id="configuration"><a class="anchorlink" href="#configuration">2.1 Configuration</a></h4>

<p>You can set up your application's default cache store by setting the
<code>config.cache_store</code> configuration option. Other parameters can be passed as
arguments to the cache store's constructor:</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = :memory_store, { size: 64.megabytes }

</pre>
</div>
<div class="note"><p>Alternatively, you can call <code>ActionController::Base.cache_store</code> outside of a configuration block.</p></div>

<p>You can access the cache by calling <code>Rails.cache</code>.</p>

<h4 id="activesupport-cache-store"><a class="anchorlink" href="#activesupport-cache-store">2.2 ActiveSupport::Cache::Store</a></h4>

<p>This class provides the foundation for interacting with the cache in Rails. This is an abstract class and you cannot use it on its own. Rather you must use a concrete implementation of the class tied to a storage engine. Rails ships with several implementations documented below.</p>

<p>The main methods to call are <code>read</code>, <code>write</code>, <code>delete</code>, <code>exist?</code>, and <code>fetch</code>. The fetch method takes a block and will either return an existing value from the cache, or evaluate the block and write the result to the cache if no value exists.</p>

<p>There are some common options that can be used by all cache implementations. These can be passed to the constructor or the various methods to interact with entries.</p>
<ul>
<li>
<code>:namespace</code> - This option can be used to create a namespace within the cache store. It is especially useful if your application shares a cache with other applications.</li>
<li>
<code>:compress</code> - Enabled by default. Compresses cache entries so more data can be stored in the same memory footprint, leading to fewer cache evictions and higher hit rates.</li>
<li>
<code>:compress_threshold</code> - Defaults to 1kB. Cache entries larger than this threshold, specified in bytes, are compressed.</li>
<li>
<code>:expires_in</code> - This option sets an expiration time in seconds for the cache entry, if the cache store supports it, when it will be automatically removed from the cache.</li>
<li>
<code>:race_condition_ttl</code> - This option is used in conjunction with the <code>:expires_in</code> option. It will prevent race conditions when cache entries expire by preventing multiple processes from simultaneously regenerating the same entry (also known as the dog pile effect). This option sets the number of seconds that an expired entry can be reused while a new value is being regenerated. It's a good practice to set this value if you use the <code>:expires_in</code> option.</li>
</ul>
<h5 id="custom-cache-stores"><a class="anchorlink" href="#custom-cache-stores">2.2.1 Custom Cache Stores</a></h5>

<p>You can create your own custom cache store by simply extending
<code>ActiveSupport::Cache::Store</code> and implementing the appropriate methods. This way,
you can swap in any number of caching technologies into your Rails application.</p>

<p>To use a custom cache store, simply set the cache store to a new instance of your
custom class.</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = MyCacheStore.new

</pre>
</div>
<h4 id="activesupport-cache-memorystore"><a class="anchorlink" href="#activesupport-cache-memorystore">2.3 ActiveSupport::Cache::MemoryStore</a></h4>

<p>This cache store keeps entries in memory in the same Ruby process. The cache
store has a bounded size specified by sending the <code>:size</code> option to the
initializer (default is 32Mb). When the cache exceeds the allotted size, a
cleanup will occur and the least recently used entries will be removed.</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = :memory_store, { size: 64.megabytes }

</pre>
</div>
<p>If you're running multiple Ruby on Rails server processes (which is the case
if you're using Phusion Passenger or puma clustered mode), then your Rails server
process instances won't be able to share cache data with each other. This cache
store is not appropriate for large application deployments. However, it can
work well for small, low traffic sites with only a couple of server processes,
as well as development and test environments.</p>

<p>New Rails projects are configured to use this implementation in development environment by default.</p>

<div class="note"><p>Since processes will not share cache data when using <code>:memory_store</code>,
it will not be possible to manually read, write, or expire the cache via the Rails console.</p></div>

<h4 id="activesupport-cache-filestore"><a class="anchorlink" href="#activesupport-cache-filestore">2.4 ActiveSupport::Cache::FileStore</a></h4>

<p>This cache store uses the file system to store entries. The path to the directory where the store files will be stored must be specified when initializing the cache.</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = :file_store, "/path/to/cache/directory"

</pre>
</div>
<p>With this cache store, multiple server processes on the same host can share a
cache. This cache store is appropriate for low to medium traffic sites that are
served off one or two hosts. Server processes running on different hosts could
share a cache by using a shared file system, but that setup is not recommended.</p>

<p>As the cache will grow until the disk is full, it is recommended to
periodically clear out old entries.</p>

<p>This is the default cache store implementation (at <code>"#{root}/tmp/cache/"</code>) if
no explicit <code>config.cache_store</code> is supplied.</p>

<h4 id="activesupport-cache-memcachestore"><a class="anchorlink" href="#activesupport-cache-memcachestore">2.5 ActiveSupport::Cache::MemCacheStore</a></h4>

<p>This cache store uses Danga's <code>memcached</code> server to provide a centralized cache for your application. Rails uses the bundled <code>dalli</code> gem by default. This is currently the most popular cache store for production websites. It can be used to provide a single, shared cache cluster with very high performance and redundancy.</p>

<p>When initializing the cache, you need to specify the addresses for all
memcached servers in your cluster. If none are specified, it will assume
memcached is running on localhost on the default port, but this is not an ideal
setup for larger sites.</p>

<p>The <code>write</code> and <code>fetch</code> methods on this cache accept two additional options that take advantage of features specific to memcached. You can specify <code>:raw</code> to send a value directly to the server with no serialization. The value must be a string or number. You can use memcached direct operations like <code>increment</code> and <code>decrement</code> only on raw values. You can also specify <code>:unless_exist</code> if you don't want memcached to overwrite an existing entry.</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = :mem_cache_store, "cache-1.example.com", "cache-2.example.com"

</pre>
</div>
<h4 id="activesupport-cache-rediscachestore"><a class="anchorlink" href="#activesupport-cache-rediscachestore">2.6 ActiveSupport::Cache::RedisCacheStore</a></h4>

<p>The Redis cache store takes advantage of Redis support for automatic eviction
when it reaches max memory, allowing it to behave much like a Memcached cache server.</p>

<p>Deployment note: Redis doesn't expire keys by default, so take care to use a
dedicated Redis cache server. Don't fill up your persistent-Redis server with
volatile cache data! Read the
<a href="https://redis.io/topics/lru-cache">Redis cache server setup guide</a> in detail.</p>

<p>For a cache-only Redis server, set <code>maxmemory-policy</code> to one of the variants of allkeys.
Redis 4+ supports least-frequently-used eviction (<code>allkeys-lfu</code>), an excellent
default choice. Redis 3 and earlier should use least-recently-used eviction (<code>allkeys-lru</code>).</p>

<p>Set cache read and write timeouts relatively low. Regenerating a cached value
is often faster than waiting more than a second to retrieve it. Both read and
write timeouts default to 1 second, but may be set lower if your network is
consistently low-latency.</p>

<p>By default, the cache store will not attempt to reconnect to Redis if the
connection fails during a request. If you experience frequent disconnects you
may wish to enable reconnect attempts.</p>

<p>Cache reads and writes never raise exceptions; they just return <code>nil</code> instead,
behaving as if there was nothing in the cache. To gauge whether your cache is
hitting exceptions, you may provide an <code>error_handler</code> to report to an
exception gathering service. It must accept three keyword arguments: <code>method</code>,
the cache store method that was originally called; <code>returning</code>, the value that
was returned to the user, typically <code>nil</code>; and <code>exception</code>, the exception that
was rescued.</p>

<p>To get started, add the redis gem to your Gemfile:</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
gem 'redis'

</pre>
</div>
<p>You can enable support for the faster <a href="https://github.com/redis/hiredis">hiredis</a>
connection library by additionally adding its ruby wrapper to your Gemfile:</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
gem 'hiredis'

</pre>
</div>
<p>Redis cache store will automatically require &amp; use hiredis if available. No further
configuration is needed.</p>

<p>Finally, add the configuration in the relevant <code>config/environments/*.rb</code> file:</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = :redis_cache_store, { url: ENV['REDIS_URL'] }

</pre>
</div>
<p>A more complex, production Redis cache store may look something like this:</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
cache_servers = %w(redis://cache-01:6379/0 redis://cache-02:6379/0)
config.cache_store = :redis_cache_store, { url: cache_servers,

  connect_timeout:    30,  # Defaults to 20 seconds
  read_timeout:       0.2, # Defaults to 1 second
  write_timeout:      0.2, # Defaults to 1 second
  reconnect_attempts: 1,   # Defaults to 0

  error_handler: -&gt; (method:, returning:, exception:) {
    # Report errors to Sentry as warnings
    Raven.capture_exception exception, level: 'warning',
      tags: { method: method, returning: returning }
  }
}

</pre>
</div>
<h4 id="activesupport-cache-nullstore"><a class="anchorlink" href="#activesupport-cache-nullstore">2.7 ActiveSupport::Cache::NullStore</a></h4>

<p>This cache store implementation is meant to be used only in development or test environments and it never stores anything. This can be very useful in development when you have code that interacts directly with <code>Rails.cache</code> but caching may interfere with being able to see the results of code changes. With this cache store, all <code>fetch</code> and <code>read</code> operations will result in a miss.</p>

<div class="code_container">
<pre class="brush: ruby; gutter: false; toolbar: false">
config.cache_store = :null_store

</pre>
</div>
</body>
</html>
